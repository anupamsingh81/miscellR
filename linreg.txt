model {
# Priors
alpha~dnorm(0, 0.0001)
beta~dnorm(0, 0.0001)
sigma~dunif(0, 100)
tau <- 1/(sigma*sigma)

# Likelihood
for (i in 1:n) {
    y[i] ~ dnorm(mu[i], tau)
    mu[i] <- alpha + beta*x[i]
}

# Derived quantities
p.decrease <- 1-step(beta) # Probability that the slope is negative, i.e., that the response decreases as the predictor increases

# Assess model fit using a sum-of-squares-type discrepancy
for (i in 1:n) {
    predicted[i] <- mu[i]             # Predicted values
    residual[i] <- y[i]-predicted[i]  # Residuals for observed data                                     
    sq[i] <- pow(residual[i], 2)      # Squared residuals

# Generate replicate data and compute fit statistics for them
    y.new[i]~dnorm(mu[i], tau)        # One new data set at each MCMC iteration
    sq.new[i] <- pow(y.new[i]-predicted[i], 2)  # Squared residuals for new data
}

fit <- sum(sq[])              # Sum of squared residuals for actual data set
fit.new <- sum(sq.new[])      # Sum of squared residuals for new data set
test <- step(fit.new-fit) 		# Test whether new data set more extreme
bpvalue <- mean(test) 		  	# Bayesian p-value
}

